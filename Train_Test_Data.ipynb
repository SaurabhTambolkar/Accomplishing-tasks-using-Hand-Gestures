{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hRwU7YK0N9dp"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Python310\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Python310\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\saura\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import imutils\n",
    "import tflearn\n",
    "import pyautogui\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from tflearn.layers.estimator import regression\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "H5WvvkLsEssl"
   },
   "outputs": [],
   "source": [
    "def Add_Data(paths):\n",
    "    images, labels = [], []\n",
    "    number_of_datasets = len(paths)\n",
    "    c = -1\n",
    "    for i in paths:\n",
    "        c += 1\n",
    "        files = os.listdir(i)\n",
    "        #num_images[i] = len()\n",
    "        for j in files: \n",
    "            images.append(cv2.cvtColor(cv2.imread(i + \"/\" + j), cv2.COLOR_BGR2GRAY).reshape(89, 100, 1))\n",
    "            z = [0 for i in range(number_of_datasets)]\n",
    "            z[c] = 1\n",
    "            labels.append(z)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KrRFeCD2Ez4x"
   },
   "outputs": [],
   "source": [
    "def CreateModel(number_of_datasets, shape_input = [None,89,100,1] ):\n",
    "    #Number of layers are changed for testing\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    net = input_data(shape = shape_input, name='input')\n",
    "    \n",
    "    net = conv_2d(net, 32, 2, activation='relu')\n",
    "    net = max_pool_2d(net, 2)\n",
    "    \n",
    "    net = conv_2d(net, 64, 2, activation='relu')\n",
    "    net = max_pool_2d(net,2)\n",
    "\n",
    "    net = conv_2d(net, 64, 2, activation='relu')\n",
    "    net = max_pool_2d(net,2)\n",
    "\n",
    "    net = conv_2d(net, 128, 2, activation='relu')\n",
    "    net = max_pool_2d(net,2)\n",
    "\n",
    "    net = conv_2d(net, 128, 2, activation='relu')\n",
    "    net = max_pool_2d(net,2)\n",
    "\n",
    "    net = conv_2d(net, 256, 2, activation='relu')\n",
    "    net = max_pool_2d(net, 2)\n",
    "\n",
    "    net = conv_2d(net, 256, 2, activation='relu')\n",
    "    net = max_pool_2d(net, 2)\n",
    "\n",
    "    net = conv_2d(net, 128, 2, activation='relu')\n",
    "    net = max_pool_2d(net, 2)\n",
    "\n",
    "    net = conv_2d(net, 64, 2, activation='relu')\n",
    "    net = max_pool_2d(net, 2)\n",
    "\n",
    "    net = fully_connected(net, 1000, activation='relu')\n",
    "    net = dropout(net, 0.75)\n",
    "\n",
    "    net = fully_connected(net, number_of_datasets, activation='softmax')\n",
    "\n",
    "    net = regression(net, optimizer='adam', learning_rate= 1e-3, loss='categorical_crossentropy', name='regression')\n",
    "\n",
    "    model = tflearn.DNN(net,tensorboard_verbose=0)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2LYnUHgaRFa2"
   },
   "outputs": [],
   "source": [
    "def ChooseAction1(selected_calss):\n",
    "  if selected_calss == 0:\n",
    "    #Move Down\n",
    "    x = list(pyautogui.position())\n",
    "    pyautogui.moveTo(x[0], x[1]+40, duration = 1)\n",
    "  elif selected_calss == 1:\n",
    "    #Move Up\n",
    "    x = list(pyautogui.position())\n",
    "    pyautogui.moveTo(x[0], x[1]-40, duration = 1)\n",
    "  elif selected_calss == 2:\n",
    "    #Move Left\n",
    "    x = list(pyautogui.position())\n",
    "    pyautogui.moveTo(x[0]-40, x[1], duration = 1)\n",
    "  elif selected_calss == 3:\n",
    "    #Move Right                       \n",
    "    x = list(pyautogui.position())\n",
    "    pyautogui.moveTo(x[0]+40, x[1], duration = 1)\n",
    "  elif selected_calss == 4:\n",
    "    #Click \n",
    "    x = list(pyautogui.position())\n",
    "    pyautogui.click(x[0], x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jBacQFefRHxD"
   },
   "outputs": [],
   "source": [
    "def ChooseAction2(selected_calss):\n",
    "  if selected_calss == 0:\n",
    "    pyautogui.press('volumeup')\n",
    "  else:\n",
    "    pyautogui.press('volumedown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "uzzw1jwqRJ_s"
   },
   "outputs": [],
   "source": [
    "def Test_Model(model, actions = 2, class_names = ['Swing','Swag'], Number_of_Frames = 30):\n",
    "  sr = False #Flag to start Recording\n",
    "  checker = None\n",
    "  frames, image_index= 0, 0\n",
    "  start_index = 0\n",
    "  camera = cv2.VideoCapture(0)\n",
    "  pt,  pb = 10, 225\n",
    "  pr, pl = 350, 590\n",
    "\n",
    "  while(1):\n",
    "      (g, f) = camera.read()\n",
    "      if g:\n",
    "          f = cv2.flip(imutils.resize(f, width=700), 1)\n",
    "          (height, width) = f.shape[:2]\n",
    "          img_cpy = f.copy()\n",
    "          gray = cv2.GaussianBlur(cv2.cvtColor(f[pt:pb, pr:pl], cv2.COLOR_BGR2GRAY), (7, 7), 0)\n",
    "          \n",
    "\n",
    "          if frames < Number_of_Frames:\n",
    "              if checker is None:\n",
    "                   checker = gray.copy().astype(\"float\")\n",
    "              else:\n",
    "                  cv2.accumulateWeighted(gray, checker, 0.5)\n",
    "          else:\n",
    "              y = cv2.threshold(cv2.absdiff(checker.astype(\"uint8\"), gray), 25, 255, cv2.THRESH_BINARY)[1]\n",
    "              (x, _) = cv2.findContours(y.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "              if 0 != len(x):\n",
    "                h = (y, max(x, key=cv2.contourArea))\n",
    "                if h is not None:\n",
    "                  (t, s) = h\n",
    "                  cv2.drawContours(img_cpy, [(pr, pt) + s], -1, (0, 0, 255))\n",
    "                  if sr == True:\n",
    "                    cv2.imwrite('x.png', t)\n",
    "                    image = Image.open('x.png')\n",
    "                    image = image.resize((100, int((float(image.size[1])*float((100/float(image.size[0])))))), Image.ANTIALIAS)\n",
    "                    image.save('x.png')\n",
    "                    image2 = cv2.imread('x.png')\n",
    "                    image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "                    selection = model.predict([image2.reshape(89, 100, 1)])\n",
    "                    len_selection = len(selection[0])\n",
    "                    total_selection = 0\n",
    "                    for _ in range(len_selection):\n",
    "                        total_selection += selection[0][_]\n",
    "                    selected_calss = np.argmax(selection)\n",
    "                    selected_calss_percentage = (np.amax(selection) / total_selection)\n",
    "                    Class_Window = np.zeros((200,520,3), np.uint8)\n",
    "                    cv2.putText(Class_Window,\"Selected Class : \" + class_names[selected_calss], (20, 20), cv2.FONT_ITALIC, 1,(255, 255, 255),2)\n",
    "                    cv2.putText(Class_Window,\"Accuracy : \" + str(100 *selected_calss_percentage) + '%', (20, 80), cv2.FONT_ITALIC, 1,(255, 255, 255),2)\n",
    "                    cv2.imshow(\"Class Info\", Class_Window)\n",
    "                    if selected_calss_percentage > 0.995:\n",
    "                      if actions == 1:\n",
    "                        k2 = cv2.waitKey(1) & 0xFF\n",
    "                        if k2 == ord(\"d\"):\n",
    "                          ChooseAction1(selected_calss)\n",
    "                      else:\n",
    "                        ChooseAction2(selected_calss)\n",
    "                  cv2.imshow(\"Gray Image\", t)\n",
    "\n",
    "          cv2.rectangle(img_cpy, (pl, pt), (pr, pb), (0, 255, 0), 2)\n",
    "          frames = frames + 1\n",
    "\n",
    "          cv2.imshow(\"Data Collection Window\", img_cpy)\n",
    "          k = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "          if  k == ord(\"q\"):\n",
    "              break\n",
    "          elif k == ord(\"a\"):\n",
    "              sr = True\n",
    "      else:\n",
    "          break\n",
    "  camera.release()\n",
    "  cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tp2kjf3QHuuy"
   },
   "source": [
    "**Train Gesturized Mouse Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Sn5mgur6E8yS"
   },
   "outputs": [],
   "source": [
    "# Add Data for Gesturized Mouse\n",
    "Train_Paths = [\"Dataset/SwingImages\", \"Dataset/PalmImages\", \"Dataset/peace\", \"Dataset/Swag\", \"Dataset/FistImages\"]\n",
    "Test_Paths = [\"Dataset/SwingTest\", \"Dataset/PalmTest\", \"Dataset/PeaceTest\", \"Dataset/SwagTest\", \"Dataset/FistTest\"]\n",
    "TrainImages, TrainLabels = Add_Data(Train_Paths)\n",
    "TestImages, TestLabels = Add_Data(Test_Paths)\n",
    "TrainImages, TrainLabels = shuffle(TrainImages, TrainLabels, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "nKi85saLHPf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 3949  | total loss: \u001b[1m\u001b[32m0.00328\u001b[0m\u001b[0m | time: 253.747s\n",
      "| Adam | epoch: 050 | loss: 0.00328 - acc: 0.9999 -- iter: 4992/5005\n",
      "Training Step: 3950  | total loss: \u001b[1m\u001b[32m0.00301\u001b[0m\u001b[0m | time: 255.047s\n",
      "| Adam | epoch: 050 | loss: 0.00301 - acc: 0.9999 | val_loss: 0.00110 - val_acc: 1.0000 -- iter: 5005/5005\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "#Train Data for Gesturized Mouse\n",
    "model = CreateModel(len(Train_Paths))\n",
    "history = model.fit(TrainImages, TrainLabels, n_epoch=50, validation_set = (TestImages, TestLabels), snapshot_step=100, show_metric=True, run_id='50412968')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "o9rPHyZHHeGo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:C:\\Users\\saura\\Downloads\\Gesture Recognition\\Models\\swi_pa_pe_swa_f\\swi_pa_pe_swa_f.tfl is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "#Save Model for Gesturized Mouse\n",
    "model.save(\"Models\\\\swi_pa_pe_swa_f\\\\swi_pa_pe_swa_f.tfl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZ6-dKLyHz5V"
   },
   "source": [
    "**Train Volume Bar Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "CyaVcQZRHzNC"
   },
   "outputs": [],
   "source": [
    "# Add Data for Volume Bar\n",
    "Train_Paths = [\"Dataset/SwingImages\", \"Dataset/Swag\"]\n",
    "Test_Paths = [\"Dataset/SwingTest\",\"Dataset/SwagTest\"]\n",
    "TrainImages, TrainLabels = Add_Data(Train_Paths)\n",
    "TestImages, TestLabels = Add_Data(Test_Paths)\n",
    "TrainImages, TrainLabels = shuffle(TrainImages, TrainLabels, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "5tfsC7FINftC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1599  | total loss: \u001b[1m\u001b[32m0.27181\u001b[0m\u001b[0m | time: 10.496s\n",
      "| Adam | epoch: 050 | loss: 0.27181 - acc: 0.9882 -- iter: 1984/2002\n",
      "Training Step: 1600  | total loss: \u001b[1m\u001b[32m0.24463\u001b[0m\u001b[0m | time: 11.868s\n",
      "| Adam | epoch: 050 | loss: 0.24463 - acc: 0.9894 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 2002/2002\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "#Train Data for Volume Bar\n",
    "model = CreateModel(len(Train_Paths))\n",
    "history2 = model.fit(TrainImages, TrainLabels, n_epoch=50, validation_set = (TestImages, TestLabels), snapshot_step=100, show_metric=True, run_id='50412968')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "R4MjOL5_Npz5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:C:\\Users\\saura\\Downloads\\Gesture Recognition\\Models\\swing_swag\\swing_swag.tfl is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "#Save Model for Gesturized Mouse\n",
    "model.save(\"Models\\\\swing_swag\\\\swing_swag.tfl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGJCBRGHRZuP"
   },
   "source": [
    "**Test Volume Bar using Swing and Swag hand Gestures**\n",
    "\n",
    "\n",
    "*   To start Testing press Key 'a' after recording windows appears\n",
    "*   To stop Press Key 'q'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "jQFWzLwMRj6D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\saura\\Downloads\\Gesture Recognition\\Models\\swing_swag\\swing_swag.tfl\n"
     ]
    }
   ],
   "source": [
    "model = CreateModel(2)\n",
    "model.load(\"Models/swing_swag/swing_swag.tfl\")\n",
    "Test_Model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNtTf4LDR7zu"
   },
   "source": [
    "**Hand Gesturized Mouse Testing**\n",
    "\n",
    "\n",
    "*   To start Testing press Key 'a' after recording windows appears\n",
    "*   To stop Press Key 'q' \n",
    "*   If you see Percentage value greater than 99.5 percentage, Press Key 'd' (Key 'd' is given for extra protection for actions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "p7c52wyGR6gv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\saura\\Downloads\\Gesture Recognition\\Models\\swi_pa_pe_swa_f\\swi_pa_pe_swa_f.tfl\n"
     ]
    }
   ],
   "source": [
    "model = CreateModel(5)\n",
    "model.load(\"Models\\\\swi_pa_pe_swa_f\\\\swi_pa_pe_swa_f.tfl\")\n",
    "Test_Model(model, actions = 1, class_names = ['Swing','Palm', 'Peace', 'Swag', 'Fist'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
